/*
Spark Tutorial Notes 
 * Hadoop is based on the concept of batch processing where the processing happens of blocks of data that have already stored
 * Spark process the data in real time faster than Hadoop 
 * Multiple Format Support -> such as Parquet, JSON, Hive and Cassandra apart from the usual formats as text files, CSV, RDMS
 * The Data Source API provides a pluggable mechanism for accessing structured data though Spark SQL
 * Spark's MLlib is the machine learning component which is handy when it comes to big data processing 
 * RDD and DAG 
 * Hadoop HDFS -> Hadoop Distributed File System - Scala Collections
 * 
*/
